{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading packages\n",
    "import PIL\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import optimizers\n",
    "from ipykernel import kernelapp as app\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file path for images\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional neural net \n",
    "\n",
    "#layer 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#layer 2\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#layer 3\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#paramters\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model parameters\n",
    "\n",
    "#iterations\n",
    "epochs = 10\n",
    "\n",
    "#training data size\n",
    "nb_train_samples = 20000\n",
    "\n",
    "#validation data size \n",
    "validation_steps = 5000\n",
    "\n",
    "#steps per iteration\n",
    "steps_per_epoch = 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, steps_per_epoch=1250, validation_data=<keras.pre..., validation_steps=5000)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 2209s 2s/step - loss: 0.4371 - acc: 0.8098 - val_loss: 0.4267 - val_acc: 0.8138\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 2271s 2s/step - loss: 0.4306 - acc: 0.8160 - val_loss: 0.4069 - val_acc: 0.8117\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 2129s 2s/step - loss: 0.4225 - acc: 0.8221 - val_loss: 0.5410 - val_acc: 0.7908\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 1972s 2s/step - loss: 0.4201 - acc: 0.8222 - val_loss: 0.3921 - val_acc: 0.8280\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 1912s 2s/step - loss: 0.4121 - acc: 0.8289 - val_loss: 0.4331 - val_acc: 0.8195\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 1996s 2s/step - loss: 0.4175 - acc: 0.8277 - val_loss: 0.3821 - val_acc: 0.8346\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 2198s 2s/step - loss: 0.4163 - acc: 0.8281 - val_loss: 0.4890 - val_acc: 0.7938\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 1932s 2s/step - loss: 0.4179 - acc: 0.8298 - val_loss: 0.5459 - val_acc: 0.8230\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 1899s 2s/step - loss: 0.4166 - acc: 0.8247 - val_loss: 0.4016 - val_acc: 0.8271\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 1838s 1s/step - loss: 0.4161 - acc: 0.8290 - val_loss: 0.3978 - val_acc: 0.8372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1209370f0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch   = steps_per_epoch,\n",
    "        validation_data   = validation_generator,\n",
    "        validation_steps  = validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save weights for later use \n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39765533608551773, 0.8373248103682122]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model \n",
    "model.evaluate_generator(validation_generator, validation_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP_chatbot",
   "language": "python",
   "name": "sp_chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
